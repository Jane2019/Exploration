# Gradient descent

This project takes a dataset that has 16 features and try to build a multivariant linear regression by:

* Direct solution by solving the formula
  
  ![image](http://www.sciweavers.org/download/Tex2Img_1584758840.jpg)

* Using cost function:

  ![image](http://www.sciweavers.org/download/Tex2Img_1584758787.jpg)

* Find solution by gradient descent

  ![image](http://www.sciweavers.org/download/Tex2Img_1584758884.jpg)

* Find solution by gradient descent with regulizer

  ![image](http://www.sciweavers.org/download/Tex2Img_1584758917.jpg)
  
* Find solution by mini-batch gradient descent: use the only batch weights to update the model weights

## Objective

  - Explore math theory inside gradient descent and use linear regression here as an example.
  - See difference between *gradient descent* and *mini-batch* and how *learning rates*, *batch size*, *regulization* have impact on converge times and train/test error.

## Good points:
  - Vectorization
  - Deep understanding in mathematics
  - How to choose hyparameters
 
